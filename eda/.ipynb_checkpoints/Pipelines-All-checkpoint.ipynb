{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "import seaborn as sns\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "# from pygeocoder import Geocoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "mm_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin = pd.read_pickle(\"../pickled_data/austin_all.pickled\")\n",
    "sanfran = pd.read_pickle(\"../pickled_data/sf_all_df.pickled\")\n",
    "LA = pd.read_pickle(\"../pickled_data/LA_new_df.pickled\")\n",
    "chicago = pd.read_pickle(\"../pickled_data/chicago_trips_df.pickled\")\n",
    "london = pd.read_pickle(\"../pickled_data/london_counts_df.pickled\")\n",
    "DC = pd.read_pickle(\"../pickled_data/DC_df.pickled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "class_model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('scaler', scaler),\n",
    "                       ('model', model)])\n",
    "pipe_class = Pipeline(steps=[('scaler', scaler),\n",
    "                       ('model', class_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Austin\n",
    "LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08109742615830821\n",
      "0.16951690550163967\n",
      "0.15147228291658688\n"
     ]
    }
   ],
   "source": [
    "austin_per_day = austin.groupby(\"dateasdatetime\").mean()\n",
    "austin_per_day[\"count\"] = austin.dateasdatetime.value_counts()\n",
    "austin_per_day.dropna(inplace=True)\n",
    "X = austin_per_day.copy()\n",
    "y = X.pop('count')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5).mean())\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.6448\n",
      "cross_val_score: 0.7645489625317212\n",
      "train_score: 0.7645714285714286\n",
      "test_score: 0.7493333333333333\n"
     ]
    }
   ],
   "source": [
    "austin_per_day = austin.groupby(\"dateasdatetime\").mean()\n",
    "austin_per_day[\"count\"] = austin.dateasdatetime.value_counts()\n",
    "mean_count = austin_per_day['count'].mean()\n",
    "list_bin = []\n",
    "for val in austin_per_day['count']:\n",
    "    if val > mean_count:\n",
    "        list_bin.append(1)\n",
    "    else:\n",
    "        list_bin.append(0)\n",
    "        \n",
    "austin_per_day['count_class'] = list_bin\n",
    "austin_per_day.dropna(inplace=True)\n",
    "del austin_per_day['count']\n",
    "X = austin_per_day.copy()\n",
    "y = X.pop('count_class')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "pipe_class.fit(X_train, y_train)\n",
    "# print(pipe.named_steps['model'].coef_)\n",
    "print('Baseline:',austin_per_day.count_class.value_counts(normalize=True).max())\n",
    "print('cross_val_score:', cross_val_score(pipe_class, X_train, y_train, cv=5).mean())\n",
    "print('train_score:',pipe_class.score(X_train, y_train))\n",
    "print('test_score:',pipe_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Fran\n",
    "LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848413493107693\n",
      "0.8717284873080158\n",
      "0.7878210684149505\n"
     ]
    }
   ],
   "source": [
    "sf_per_day = sanfran.groupby([sanfran[\"start_date\"].dt.date]).mean()\n",
    "sf_per_day[\"count\"] = sanfran.groupby([sanfran[\"start_date\"].dt.date]).count()[\"mean_temperature_c\"]\n",
    "sf_per_day.dropna(inplace=True)\n",
    "X = sf_per_day.copy()\n",
    "y = X.pop('count')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5).mean())\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))\n",
    "# print(pipe.named_steps['model'].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.5858725761772853\n",
      "cross_val_score: 0.9326899631139585\n",
      "train_score: 0.9623762376237623\n",
      "test_score: 0.9124423963133641\n"
     ]
    }
   ],
   "source": [
    "sf_per_day = sanfran.groupby([sanfran[\"start_date\"].dt.date]).mean()\n",
    "sf_per_day[\"count\"] = sanfran.groupby([sanfran[\"start_date\"].dt.date]).count()[\"mean_temperature_c\"]\n",
    "mean_count = austin_per_day['count'].mean()\n",
    "list_bin = []\n",
    "for val in sf_per_day['count']:\n",
    "    if val > mean_count:\n",
    "        list_bin.append(1)\n",
    "    else:\n",
    "        list_bin.append(0)\n",
    "        \n",
    "sf_per_day['count_class'] = list_bin\n",
    "sf_per_day.dropna(inplace=True)\n",
    "del sf_per_day['count']\n",
    "X = sf_per_day.copy()\n",
    "y = X.pop('count_class')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "pipe_class.fit(X_train, y_train)\n",
    "# print(pipe.named_steps['model'].coef_)\n",
    "print('Baseline:',sf_per_day.count_class.value_counts(normalize=True).max())\n",
    "print('cross_val_score:', cross_val_score(pipe_class, X_train, y_train, cv=5).mean())\n",
    "print('train_score:',pipe_class.score(X_train, y_train))\n",
    "print('test_score:',pipe_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicago "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London\n",
    "LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981013700336702\n",
      "0.8070210648840047\n",
      "0.7200972039823934\n"
     ]
    }
   ],
   "source": [
    "london_per_day = london.groupby([london[\"timestamp\"].dt.date]).mean()\n",
    "london_per_day.head()\n",
    "X = london_per_day.copy()\n",
    "y = X.pop('cnt')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5).mean())\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.510958904109589\n",
      "0.874814391776128\n",
      "0.8747553816046967\n",
      "0.867579908675799\n"
     ]
    }
   ],
   "source": [
    "london_per_day = london.groupby([london[\"timestamp\"].dt.date]).mean()\n",
    "del london_per_day['is_weekend']\n",
    "del london_per_day['hum_binary']\n",
    "del london_per_day['t2']\n",
    "mean_count = london_per_day['cnt'].mean()\n",
    "list_bin = []\n",
    "for val in london_per_day['cnt']:\n",
    "    if val > mean_count:\n",
    "        list_bin.append(1)\n",
    "    else:\n",
    "        list_bin.append(0)\n",
    "        \n",
    "london_per_day['count_class'] = list_bin\n",
    "del london_per_day['cnt']\n",
    "X = london_per_day.copy()\n",
    "y = X.pop('count_class')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "pipe_class.fit(X_train, y_train)\n",
    "print('Baseline:',london_per_day.count_class.value_counts(normalize=True).max())\n",
    "print(cross_val_score(pipe_class, X_train, y_train, cv=5).mean())\n",
    "print(pipe_class.score(X_train, y_train))\n",
    "print(pipe_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC \n",
    "LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995993558776812\n",
      "0.999642496662489\n",
      "0.9989569797127122\n"
     ]
    }
   ],
   "source": [
    "dc_per_day = DC.groupby([DC[\"datetime\"].dt.date]).mean()\n",
    "dc_per_day[\"count\"] = (DC[\"count\"].groupby([DC[\"datetime\"].dt.date]).sum())\n",
    "\n",
    "X = dc_per_day.copy()\n",
    "y = X.pop('count')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5).mean())\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.5087719298245614\n",
      "0.9718192918192919\n",
      "0.9811912225705329\n",
      "0.9781021897810219\n"
     ]
    }
   ],
   "source": [
    "dc_per_day = DC.groupby([DC[\"datetime\"].dt.date]).mean()\n",
    "dc_per_day[\"count\"] = (DC[\"count\"].groupby([DC[\"datetime\"].dt.date]).sum())\n",
    "mean_count = dc_per_day['count'].mean()\n",
    "list_bin = []\n",
    "for val in dc_per_day['count']:\n",
    "    if val > mean_count:\n",
    "        list_bin.append(1)\n",
    "    else:\n",
    "        list_bin.append(0)\n",
    "                \n",
    "dc_per_day['count_class'] = list_bin\n",
    "del dc_per_day['count']\n",
    "X = dc_per_day.copy()\n",
    "y = X.pop('count_class')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=1)\n",
    "pipe_class.fit(X_train, y_train)\n",
    "print('Baseline:',dc_per_day.count_class.value_counts(normalize=True).max())\n",
    "print(cross_val_score(pipe_class, X_train, y_train, cv=5).mean())\n",
    "print(pipe_class.score(X_train, y_train))\n",
    "print(pipe_class.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
